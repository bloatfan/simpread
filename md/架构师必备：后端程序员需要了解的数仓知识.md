> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [mp.weixin.qq.com](https://mp.weixin.qq.com/s/XQm0biyBYJtKlijsm7saMA)

大家好，我是 Java 烘焙师。后端程序员平时除了接触业务代码、中间件、存储等，也难免会跟数仓有交集。下面结合笔者的经验和思考，从后端程序员的视角看数仓、做个总结，后续再跟数仓 / BI argue 的时候就不虚了😃

分成两部分介绍：离线数仓、实时数仓。

离线数仓
====

离线数仓是最典型的数仓应用场景。后端服务产生了业务数据、监控埋点、日志等，如果要做统计分析，就要先离线采集到数仓，再通过 SQL 做聚合查询。 离线数仓的重点，在于统计分析历史存量数据，做合理的业务域划分、数据分层、数据分区。

![](https://raw.githubusercontent.com/bloatfan/PicGo/master/2026/01/29/640%3Fwx_fmt%3Dpng%26from%3Dappmsg%26watermark%3D1%23imgIndex%3D0)

数据采集
----

需要采集的数据包括：业务数据、监控埋点、日志等。

*   业务数据：一般存储在 DB、或 HBase，可一次性把存量数据导入 hive 表，后续定时扫描一段时间范围内的增量数据导入 hive 表
    
*   监控埋点：后端服务发出埋点消息，采集程序消费消息、解析、最终导入到 hive 表
    
*   日志：可通过 filebeat 采集日志，采集程序解析后、导入到 hive 表
    

数据分层
----

逻辑层面的水平数据分层：

*   `ODS (Operational Data Store)`：原始数据，一般不做任何加工
    
*   `DWD (Data Warehouse Detail)`：数仓明细数据，在 ODS 的基础上做一些简单加工，如数据清洗，解析 json 格式字段、打平后存储
    
*   `DWS (Data WareHouse Summary)`：数仓汇总数据，在 DWD 的基础上按维度做聚合宽表，方便业务方使用
    
*   `ADS (Application Data Service)`：直接可用的报表应用数据
    

离线数仓的数据分层，类似于后端代码结构的分层设计，比如分为接口层 interface、逻辑层 service、数据访问层 repository。 数据分层可以隔离每层之间的依赖，每层的变更只限于本层。比如 mysql 拆库迁移只需要更换 ods 表，但无需改 dwd 表，这样数据使用方不用感知数据源变更。 数据分层可以在 DW 层聚合数据，提高数据使用方的效率、降低开发成本。

后端程序员接触最多的是 ods 和 dwd 表：

*   ods 表涉及到数据采集，并且是归档删在线数据的前提
    
*   dwd 表可以用来排查历史数据，因为 json 格式字段已打平，所以方便做筛选查询
    

数据分区
----

按时间维度做垂直分区，一般是日级或小时级分区，取决于调度频率：

*   天级增量表：包含某一天有变更的数据记录
    
*   天级全量表：包含某一天完整的数据记录，相当于快照
    
*   小时级增量表：包含某一小时有变更的数据记录
    

因为数据量较大，所以不是所有的离线表都会永久保留。比如 ods 天级增量表可能仅保留最近 n 天、或最近 n 个分区，而 dwd 天级全量表会 merge 增量数据，可查到历史上的所有数据记录。

离线数仓使用场景
--------

*   离线统计：
    

*   通过 hive sql 做复杂的关联查询、聚合查询，底层会转成 MapReduce 任务，查询 HDFS 里的 hive 表
    
*   比如把多张事实表、维度表 join 起来，做某个维度的数量加总、金额加总。事实表是业务活动的事件记录，可以做聚合查询统计。维度表是元数据，按维度做聚合分析（max、count，group by 维度）。事实表一般包含多个维度表的外键。
    

*   数据对账：判断业务双方的数据是否一致，参考笔者之前写的文章：[架构师必备：实时对账与离线对账](https://mp.weixin.qq.com/s?__biz=MzkyNjM3NjY5Ng==&mid=2247483883&idx=1&sn=d863f879d5bbd7b70f596ad693a95d66&scene=21#wechat_redirect)
    
*   后端刷历史存量数据：需要先在离线统计符合条件的数据，再导出 id 消息，作为后端刷数据的输入依据
    

后端归档删除在线数据
----------

后端在线数据不断膨胀，当业务层面不再访问时，需要做归档删除。一定要确保业务数据先被离线采集到、再删除在线数据，否则就可能丢数据、找不回来了。 比如新增一个`archive_status`字段代表归档状态（而非有业务含义的`deleted`字段），初始值是 0，被软删后改成 1，那么如果 hive 表里记录的归档状态是 1，则代表该记录已被离线采集到，可放心地删除对应在线记录。

实时数仓
====

有了离线数仓，为什么还需要实时数仓呢？

*   主要还是为了时效性，离线数仓最快是小时级，如果需要秒级延迟，就需要上实时数仓了
    
*   实时数仓跑出来的结果，可以被后端服务查询，用于在线业务
    

实时数仓的重点，在于低延迟计算、exactly-once 处理，与后端应用结合可以实现很多功能。

实时数仓构建流程
--------

使用 flink 把数据采集、数据计算、数据导出的流程串起来。这里引用一张某云厂商的实践教程图，里面的数仓存储可替代为其它。 参考：https://help.aliyun.com/zh/flink/realtime-flink/use-cases/build-real-time-data-warehouse-based-on-flink-hologres![](https://raw.githubusercontent.com/bloatfan/PicGo/master/2026/01/29/640%3Fwx_fmt%3Dpng%26from%3Dappmsg%26watermark%3D1%23imgIndex%3D1)

*   实时入仓：mysql binlog、或业务事件，触发实时数据流，通过 flink 实时入仓
    
*   数据计算：通过 flink 关联 join 多个 ods 表，得到 dwd 表，再实时计算得到按维度聚合的 dws 表
    
*   数据导出、对外提供接口查询：计算结果可导出到实时数仓，如 Doris、Hologres 等，也可以导出到 mysql、hbase、或 redis，并封装成 RPC 接口。这样后端服务可以查询实时数仓接口，对外提供高 qps 查询
    

实时数仓使用场景
--------

*   内部报表查询
    
*   外部统计类查询：典型的例如用户看到的 排行榜、多少人看过 / 加购 / 收藏 / 买过 等
    
*   用户个性化推荐
    

以上，就是后端程序员需要了解的数仓知识了，欢迎关注、转发、点赞。